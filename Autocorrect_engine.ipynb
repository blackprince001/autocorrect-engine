{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Autocorrect System\n",
    "\n",
    "An autocorrect system predicts that likelihood of a mispelled word to the correct one.\n",
    "\n",
    "## Steps for Implementing an autocorrect system\n",
    "\n",
    "    1. Identify the mispelled word\n",
    "    2. Find strings that are `n` edit distance away from the mispelled word\n",
    "    3. Filter suggested candidates to retain only one found in the vocabulary\n",
    "    4. Order filtered candidates based on word probabilities\n",
    "    5. Predict the most likely candidate\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Identify a mispelled word\n",
    "\n",
    "A word is mispelled if it is not found in the vocabulary of the corpus of text the autocorrect system is working with\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions for reading texts from files and parsing them into proper data for manipulation.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def read_corpus(filename: object) -> list:\n",
    "    \"\"\" Converts filecontents of the filepath(filename)\n",
    "        into a dictionary list  \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        words = []\n",
    "\n",
    "        for line in lines:\n",
    "            words.append(line)\n",
    "\n",
    "    dictionary = [word.strip('\\n\\r') for word in words]\n",
    "    dictionary = [lower.lower() for lower in dictionary]\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def read_corpus_dataref(filename: object) -> list:\n",
    "    \"\"\" Converts filecontents of the filepath(filename)\n",
    "        into a dictionary list\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        words = []\n",
    "        for line in lines:\n",
    "            words += re.findall(r'\\w+', line.lower())\n",
    "\n",
    "    dictionary = [word.strip('\\n\\r') for word in words]\n",
    "\n",
    "    return dictionary\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from the text file Dictionary.txt and letter.txt into `dictionary` and `data` variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "dictionary = read_corpus('./dictionary.txt')\n",
    "data = read_corpus_dataref('./letter.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions to manipulate text from the dictionary list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def split_word(word: str) -> list:\n",
    "    \"\"\" Splits words into syllabi \"\"\"\n",
    "    return [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "\n",
    "def insert_word(word: str) -> list:\n",
    "    \"\"\" Inserts words into split words \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return [l + c + r for l,r in split_word(word) for c in letters]\n",
    "\n",
    "def delete_word(word: str) -> list:\n",
    "    \"\"\" Deletes words and letters from split words \"\"\"\n",
    "    return [l + r[1:] for l,r in split_word(word) if r]\n",
    "\n",
    "def swap_word(word: str) -> list:\n",
    "    \"\"\" Swaps positions of words in split words \"\"\"\n",
    "    return [l+r[1]+r[0]+r[2:] for l,r in split_word(word) if len(r) > 1]\n",
    "\n",
    "def replace_word(word: str) -> list:\n",
    "    \"\"\" Replaces words and letters in split words \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return [l+c+r[1:] for l,r in split_word(word) if r for c in letters]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing levels of Editing to suggest better words from data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "  \n",
    "\n",
    "def level_one_edit(word: str) -> list:\n",
    "    return set(delete_word(word)+swap_word(word)+replace_word(word)+insert_word(word))\n",
    "\n",
    "def level_two_edit(word: str) -> list:\n",
    "    return set(two_edit for two_edits in level_one_edit(word) for two_edit in level_one_edit(two_edits))\n",
    "\n",
    "def correct_spelling(word: str, dictionary: list, word_probabilities: float) -> list:\n",
    "    if word in dictionary:\n",
    "        return 0\n",
    "\n",
    "    suggestions = level_one_edit(word) or level_two_edit(word) or [word]\n",
    "    best_guesses = [w for w in suggestions if w in dictionary]\n",
    "    \n",
    "    return sorted([(w, word_probabilities[w]) for w in best_guesses]) \n",
    "\n",
    "\n",
    "vocabs = set(data)\n",
    "word_count = Counter(data)\n",
    "total_count = float(sum(word_count.values()))\n",
    "word_probability = {dict_word: word_count[dict_word]/total_count for dict_word in word_count.keys()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "wrong_spelling = 'blakc'\n",
    "best = correct_spelling(wrong_spelling, dictionary=vocabs, word_probabilities=word_probability)\n",
    "print(f' For the incorrectly spelt word: \"{wrong_spelling}\", the Most likely word(s) to be correct is/are: \"{best}\"')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " For the incorrectly spelt word: \"blakc\", the Most likely word(s) to be correct is/are: \"[('black', 0.00033670593516955846), ('blake', 2.0784316985775213e-06), ('blanc', 1.0392158492887607e-06)]\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running tests on a text file or stream of text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def change(n_tuple: tuple) -> tuple:\n",
    "    return sorted(n_tuple)[0]\n",
    "\n",
    "def parse_text(text: str) -> str:\n",
    "    lines = text\n",
    "    words = []\n",
    "\n",
    "    for line in lines:\n",
    "        words += re.findall(r'\\w+', line.lower())\n",
    "\n",
    "    parsed_text = [word.strip('\\n\\r') for word in words]\n",
    "    return parsed_text\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "sample_text = \"\"\"Thsi is how it's going to make prediactions\"\"\"\n",
    "for i in sample_text.lower().split():\n",
    "    best = correct_spelling(i, vocabs, word_probability)\n",
    "    if best == 0:\n",
    "        continue\n",
    "    print(f'\"{i}\" can be replaced with \"{best}\"\\n')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"thsi\" can be replaced with \"[('phsi', 1.0392158492887607e-06), ('thei', 2.0784316985775213e-06), ('thi', 2.0784316985775213e-06), ('this', 0.003951098658995868)]\"\n",
      "\n",
      "\"it's\" can be replaced with \"[('its', 0.0011306668440261717), ('itus', 5.196079246443803e-06)]\"\n",
      "\n",
      "\"prediactions\" can be replaced with \"[('predictions', 2.0784316985775213e-06)]\"\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## YAY!, Everything is working great.\n",
    "\n",
    "'thsi' is highly replaceable by 'this' with 0.00039 based on the corpus used. Greater dataset for the use of this can greatly increase it's probabilty even it already has the highest amongst the rest of the predictions made."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}